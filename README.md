

---

# ğŸŒ¸ MLOps Week 4 Assignment: CI/CD Pipeline for Iris Model

This repository demonstrates a **Continuous Integration (CI)** pipeline for a machine learning project â€” built as part of an **MLOps assignment**.
It uses the classic **Iris dataset** to train a **Decision Tree Classifier** and implement a full CI workflow using **GitHub Actions**, **DVC**, and **CML**.

---

## âœ… Objectives Covered

This project successfully implements the following **MLOps best practices**:

* **Git Repository Setup**: Established a standard branching strategy with `main` and `dev` branches.
* **Automated Testing**: Created data validation and model evaluation unit tests using `pytest`.
* **Continuous Integration (CI)**: Configured a CI pipeline using **GitHub Actions** that triggers on pushes and pull requests.
* **Data & Model Versioning Integration**: The CI pipeline fetches versioned datasets and models from a **DVC remote (Google Cloud Storage)** before running tests.
* **Automated Reporting**: On every pull request, a **sanity test report** is automatically generated and posted as a comment using **CML (Continuous Machine Learning)**.

---

## ğŸ§© Development Workflow Overview

The development follows a **standard Git flow**, enhanced with MLOps automation:

1. **Branching** â€“ Create a new feature branch from `dev`.
2. **Development** â€“ Make code changes (e.g., model improvements, new tests).
3. **Push** â€“ Push the feature branch to GitHub.
4. **Pull Request** â€“ Open a PR to merge into `dev` or `main`.
5. **CI Automation** â€“ The GitHub Actions workflow:

   * Sets up a clean environment
   * Installs dependencies
   * Authenticates with the DVC remote
   * Pulls versioned data and model
   * Runs `pytest` for validation and evaluation
   * Posts a **CML report** with test results in the PR
6. **Review & Merge** â€“ Merge after successful checks and approval.

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ .dvc/                   # DVC configuration files
â”œâ”€â”€ .github/workflows/      # GitHub Actions CI/CD workflow definitions
â”‚   â””â”€â”€ ci.yml
â”œâ”€â”€ artifacts/              # Model outputs (tracked by DVC)
â”‚   â””â”€â”€ model.joblib.dvc
â”œâ”€â”€ data/                   # Datasets (tracked by DVC)
â”‚   â””â”€â”€ iris.csv.dvc
â”œâ”€â”€ .dvcignore              # Files for DVC to ignore
â”œâ”€â”€ .gitignore              # Files for Git to ignore
â”œâ”€â”€ README.md               # Project documentation
â”œâ”€â”€ requirements.txt        # Project dependencies
â”œâ”€â”€ test_model_validation.py # Pytest unit tests
â””â”€â”€ train.py                # Model training script
```

---

## ğŸš€ How to Run Locally

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/Shridhar7-8/week-4-mlops.git
cd week-4-mlops
```

### 2ï¸âƒ£ Set up a virtual environment

```bash
python3 -m venv venv
source venv/bin/activate  # (For Windows: venv\Scripts\activate)
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configure DVC remote (optional)

Youâ€™ll need your own **GCS bucket** and **service account credentials**.
If youâ€™re using your own DVC remote:

```bash
dvc remote modify gcs_remote gcs_bucket_name <your-bucket-name>
```

### 5ï¸âƒ£ Pull data and model from DVC

```bash
dvc pull
```

### 6ï¸âƒ£ Run tests

```bash
pytest --verbose
```

---

â­ **This project demonstrates a simple yet complete CI/CD pipeline for ML workflows â€” integrating data versioning, testing, and reporting into a reproducible process.**

---



